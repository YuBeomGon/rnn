{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8816901-b324-4e61-9d44-3f832210d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "# https://jaketae.github.io/study/pytorch-rnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1ea438-cab6-49de-ac4b-b0e223320df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from string import ascii_letters\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from unidecode import unidecode\n",
    "\n",
    "_ = torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e297bed2-04f2-4b28-ba8f-210523f350af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/names\"\n",
    "\n",
    "lang2label = {\n",
    "    file_name.split(\".\")[0]: torch.tensor([i], dtype=torch.long)\n",
    "    for i, file_name in enumerate(os.listdir(data_dir))\n",
    "}\n",
    "\n",
    "num_langs = len(lang2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b077664e-3420-4088-b09c-be11a643b6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'English': tensor([0]),\n",
       " 'Spanish': tensor([1]),\n",
       " 'Arabic': tensor([2]),\n",
       " 'Russian': tensor([3]),\n",
       " 'Vietnamese': tensor([4]),\n",
       " 'Korean': tensor([5]),\n",
       " 'French': tensor([6]),\n",
       " 'Portuguese': tensor([7]),\n",
       " 'Italian': tensor([8]),\n",
       " 'Polish': tensor([9]),\n",
       " 'Greek': tensor([10]),\n",
       " 'Irish': tensor([11]),\n",
       " 'Japanese': tensor([12]),\n",
       " 'Chinese': tensor([13]),\n",
       " 'Scottish': tensor([14]),\n",
       " 'German': tensor([15]),\n",
       " 'Dutch': tensor([16]),\n",
       " 'Czech': tensor([17])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c63288c-bbc2-41cf-9012-4b9e20ec1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f5bd728-51e0-4b92-8e0c-185b87125c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Slusarski'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unidecode(\"Ślusàrski\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aaf4de0-dcf9-4b86-9f14-9eff9a5197b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2idx = {letter: i for i, letter in enumerate(ascii_letters + \" .,:;-'\")}\n",
    "num_letters = len(char2idx)\n",
    "num_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4046069-c229-47ab-bb46-1522f38acf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "162f35ee-eb9a-4ca6-bc07-771098ef226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name2tensor(name):\n",
    "    tensor = torch.zeros(len(name), 1, num_letters)\n",
    "    for i, char in enumerate(name):\n",
    "        tensor[i][0][char2idx[char]] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e7fb903-96d8-422b-bfc6-a0a95caa5381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2tensor(\"abZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cd21074-d1ed-44da-b773-de94bea63176",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_names = []\n",
    "target_langs = []\n",
    "\n",
    "for file in os.listdir(data_dir):\n",
    "    with open(os.path.join(data_dir, file)) as f:\n",
    "        lang = file.split(\".\")[0]\n",
    "        names = [unidecode(line.rstrip()) for line in f]\n",
    "        for name in names:\n",
    "            try:\n",
    "                tensor_names.append(name2tensor(name))\n",
    "                target_langs.append(lang2label[lang])\n",
    "            except KeyError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f0473e5-f472-45fd-afdb-d1354301179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91ceabc8-a786-4341-9de3-cb26d146334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    range(len(target_langs)), \n",
    "    test_size=0.1, \n",
    "    shuffle=True, \n",
    "    stratify=target_langs,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "train_dataset = [\n",
    "    (tensor_names[i], target_langs[i])\n",
    "    for i in train_idx\n",
    "]\n",
    "\n",
    "test_dataset = [\n",
    "    (tensor_names[i], target_langs[i])\n",
    "    for i in test_idx\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16be7c00-5d31-4f09-a608-0e0c6d14f0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 59])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names, labels = next(iter(train_dataset))\n",
    "names.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d6d8a79-9d7b-4a2d-aa49-c9184bc3ee9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 18063\n",
      "Test: 2007\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {len(train_dataset)}\")\n",
    "print(f\"Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "890e3b6e-6a5a-4521-b5f5-b0f16abf42c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input2hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden2hidden = nn.Linear(hidden_size, hidden_size)\n",
    "        self.hidden2output = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        torch.nn.init.normal(self.input2hidden.weight, mean=0., std=0.05)\n",
    "        torch.nn.init.normal(self.hidden2hidden.weight, mean=0., std=0.05)\n",
    "        torch.nn.init.normal(self.hidden2output.weight, mean=0., std=0.05)\n",
    "        \n",
    "        torch.nn.init.zeros_(self.input2hidden.bias)\n",
    "        torch.nn.init.zeros_(self.hidden2hidden.bias)\n",
    "        torch.nn.init.zeros_(self.hidden2output.bias)        \n",
    "    \n",
    "    def forward(self, x, hidden_state):\n",
    "        embeding = self.input2hidden(x)\n",
    "        hidden_state = self.hidden2hidden(hidden_state)\n",
    "        combined = torch.mean(torch.stack([embeding, hidden_state]), dim=0)\n",
    "        # hidden = torch.sigmoid(combined)\n",
    "        hidden = torch.tanh(combined)\n",
    "        output = self.hidden2output(combined)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # return nn.init.kaiming_uniform_(torch.empty(1, self.hidden_size))\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71fa2c3f-586b-4bd8-95d9-ac4a008eb202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 256 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/.local/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  if __name__ == '__main__':\n",
      "/home/beomgon/.local/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/beomgon/.local/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "learning_rate = 0.001\n",
    "\n",
    "print(num_letters, hidden_size, num_langs)\n",
    "\n",
    "model = MyRNN(num_letters, hidden_size, num_langs)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "564caf53-afad-40cb-9446-550264d94168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc() :    \n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = len(test_dataset)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for name, label in test_dataset:\n",
    "            hidden_state = model.init_hidden()\n",
    "            for char in name:\n",
    "                output, hidden_state = model(char, hidden_state)\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            num_correct += bool(pred == label)\n",
    "            \n",
    "    model.train()\n",
    "\n",
    "    print(f\"Accuracy: {num_correct / num_samples * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49dacd7a-0d78-406a-9d57-0328f772827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [3000/18063], Loss: 0.0002\n",
      "Accuracy: 59.4918%\n",
      "Epoch [1/4], Step [6000/18063], Loss: 0.0126\n",
      "Accuracy: 63.7270%\n",
      "Epoch [1/4], Step [9000/18063], Loss: 2.9937\n",
      "Accuracy: 65.0224%\n",
      "Epoch [1/4], Step [12000/18063], Loss: 1.2562\n",
      "Accuracy: 67.7628%\n",
      "Epoch [1/4], Step [15000/18063], Loss: 0.0025\n",
      "Accuracy: 65.3214%\n",
      "Epoch [1/4], Step [18000/18063], Loss: 0.0158\n",
      "Accuracy: 69.0085%\n",
      "Epoch [2/4], Step [3000/18063], Loss: 0.0026\n",
      "Accuracy: 69.9552%\n",
      "Epoch [2/4], Step [6000/18063], Loss: 0.1379\n",
      "Accuracy: 67.8625%\n",
      "Epoch [2/4], Step [9000/18063], Loss: 0.0000\n",
      "Accuracy: 69.4569%\n",
      "Epoch [2/4], Step [12000/18063], Loss: 0.0004\n",
      "Accuracy: 71.0513%\n",
      "Epoch [2/4], Step [15000/18063], Loss: 0.0086\n",
      "Accuracy: 71.6492%\n",
      "Epoch [2/4], Step [18000/18063], Loss: 2.8589\n",
      "Accuracy: 71.4499%\n",
      "Epoch [3/4], Step [3000/18063], Loss: 0.0000\n",
      "Accuracy: 72.9447%\n",
      "Epoch [3/4], Step [6000/18063], Loss: 0.0016\n",
      "Accuracy: 71.9980%\n",
      "Epoch [3/4], Step [9000/18063], Loss: 0.0082\n",
      "Accuracy: 69.1579%\n",
      "Epoch [3/4], Step [12000/18063], Loss: 0.2083\n",
      "Accuracy: 71.5496%\n",
      "Epoch [3/4], Step [15000/18063], Loss: 5.0456\n",
      "Accuracy: 72.4963%\n",
      "Epoch [3/4], Step [18000/18063], Loss: 0.1802\n",
      "Accuracy: 72.8949%\n",
      "Epoch [4/4], Step [3000/18063], Loss: 0.0009\n",
      "Accuracy: 71.9980%\n",
      "Epoch [4/4], Step [6000/18063], Loss: 0.0024\n",
      "Accuracy: 71.9980%\n",
      "Epoch [4/4], Step [9000/18063], Loss: 0.0140\n",
      "Accuracy: 73.5924%\n",
      "Epoch [4/4], Step [12000/18063], Loss: 4.8560\n",
      "Accuracy: 74.1903%\n",
      "Epoch [4/4], Step [15000/18063], Loss: 0.0059\n",
      "Accuracy: 72.5461%\n",
      "Epoch [4/4], Step [18000/18063], Loss: 0.0662\n",
      "Accuracy: 73.0942%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 4\n",
    "print_interval = 3000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    random.shuffle(train_dataset)\n",
    "    for i, (name, label) in enumerate(train_dataset):\n",
    "        hidden_state = model.init_hidden()\n",
    "        for char in name:\n",
    "            output, hidden_state = model(char, hidden_state)\n",
    "            # print(output)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % print_interval == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                f\"Step [{i + 1}/{len(train_dataset)}], \"\n",
    "                f\"Loss: {loss.item():.4f}\"\n",
    "            )\n",
    "            get_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae3f2641-b01a-449c-aa19-0f42209d8d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.4928%\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_samples = len(test_dataset)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for name, label in test_dataset:\n",
    "        hidden_state = model.init_hidden()\n",
    "        for char in name:\n",
    "            output, hidden_state = model(char, hidden_state)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        num_correct += bool(pred == label)\n",
    "\n",
    "print(f\"Accuracy: {num_correct / num_samples * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc0d8f-c8e1-48ae-aaac-4490089e4ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
